if(!require(stabledist)) {install.packages("stabledist"); library(stabledist)}
if(!require(Runuran)) {install.packages("Runuran"); library(Runuran)}
if(!require(copula)) {install.packages("copula"); library(copula)}
if(!require(VineCopula)) {devtools::install_github("tnagler/VineCopula"); library(VineCopula)}

# Functions to fit stable distibution
	# # Making dist and prob functions for fitting
	# # Note that
	# alpha = 2*exp(a)/(1+exp(a))
	# beta = (exp(b)-1)/(exp(b)+1)
	# gamma = exp(c)
	# delta = d
dstfit = function(u, a, b, c, d) {
	alpha = 2*exp(a)/(1+exp(a));
	beta = (exp(b)-1)/(exp(b)+1);
	gamma = exp(c);
	delta = d;
	cat(a,b,c,d,"\n");
	return(dstable(u, alpha, beta, gamma, delta)); }
pstfit = function(q, a, b, c, d) {
	alpha = 2*exp(a)/(1+exp(a));
	beta = (exp(b)-1)/(exp(b)+1);
	gamma = exp(c);
	delta = d;
	cat(a,b,c,d,"\n");
	return(pstable(q, alpha, beta, gamma, delta)); }
qstfit = function(p, a, b, c, d) {
	alpha = 2*exp(a)/(1+exp(a));
	beta = (exp(b)-1)/(exp(b)+1);
	gamma = exp(c);
	delta = d;
	cat(a,b,c,d,"\n");
	return(qstable(p, alpha, beta, gamma, delta)); }


# Meixner distribution

# Meixner PDF
dmeixner <- function(u, alpha, beta, delta, mu) {
	distr <- udmeixner(alpha, beta, delta, mu);
	gen <- pinvd.new(distr);
	ud(gen, u);
}

# Meixner CDF
pmeixner <- function(q, alpha, beta, delta, mu) {
	distr <- udmeixner(alpha, beta, delta, mu);
	gen <- pinvd.new(distr);
	up(gen, q);
}

# Quantile function of Meixner dist
qmeixner <- function(p, alpha, beta, delta, mu) {
	distr <- udmeixner(alpha, beta, delta, mu);
	gen <- pinvd.new(distr);
	uq(gen, p);
}

# Random value generator with Mexiner dist
rmeixner <- function(n, alpha, beta, delta, mu) {
	distr <- udmeixner(alpha, beta, delta, mu);
	gen <- pinvd.new(distr);
	ur(gen, n);
}


# Function to generate a sample normal copula
boot.nCopula <- function(data, procedures = 200, N = nrow(data)) {
	# data is our observations
	# procedures - number of bootstrap loops
	# n - number of simulated points to every procedure
	Dim <- ncol(data) # dimension of copula
	rows <- nrow(data) # number of data points
	data <- as.matrix(data)
	replicate(procedures, {
		samples <- sample(1:rows, replace=T) # random numbers
		dataBoot <- data[samples,] # generate data bootstrap
		x <- pobs(dataBoot) # pseudo-observations
		# Fit the copula
		cop.Fit <- fitCopula(normalCopula(dim=Dim, dispstr='un'), data=x,
								method='itau')
		# Parameters' estimate
		R <- coef(cop.Fit)
		# Show the progress
		cat('=')
		# Generate the copula
		rCopula(N, normalCopula(param=R, dim=Dim, dispstr='un')) 
	}
)}

boot.tCopula <- function(data, procedures = 200, N = nrow(data)) {
	# data is our observations
	# procedures - number of bootstrap loops
	# n - number of simulated points to every procedure
	Dim <- ncol(data) # dimension of copula
	rows <- nrow(data) # number of data points
	data <- as.matrix(data)
	replicate(procedures, {
		samples <- sample(1:rows, replace=T) # random numbers
		dataBoot <- data[samples,] # generate data bootstrap
		x <- pobs(dataBoot) # pseudo-observations
		# Fit the copula
		cop.Fit <- fitCopula(tCopula(dim=Dim, dispstr='un'), data=x, 
				method='itau.mpl')
		# Parameters' estimate
		par <- coef(cop.Fit)
		R <- par[-length(par)]
		df <- min(10, round(par[length(par)]))
		# Show the progress
		cat('=')
		# Generate the copula
		rCopula(N, tCopula(param=R, df=df, dim=Dim, dispstr='un', df.fixed=T)) 
	}
)}

VaR.bootstrap <- function(data, boot.pobs, weights, probs) {
	# data is our observations
	# boot - simulated pseudo-observations of several bootstrap copulas, 
	# generated by "scenarioGenerate" function
	# weights - portfolio weights, which we calculate VaR for
	Dim <- ncol(data)
	apply(boot.pobs, 3, function(b) {
		ret_i <- apply(data, 2, function(d) quantile(d, b))
		ret <- ret_i %*% weights
		quantile(-ret, probs) } 
)}

ES.bootstrap <- function(data, boot.pobs, weights, probs) {
  # data is our observations
  # boot - simulated pseudo-observations of several bootstrap copulas, 
  # generated by "scenarioGenerate" function
  # weights - portfolio weights, which we calculate VaR for
  Dim <- ncol(data)
  apply(boot.pobs, 3, function(b) {
    ret_i <- apply(data, 2, function(d) quantile(d, b))
    ret <- ret_i %*% weights
    sapply(probs, function(p) mean(-ret[-ret > quantile(-ret, probs=p)]))}
)}

# Generate scenarios without arbitrage by multivariate distriution function
scenarioGenerate <- function(N, Mvdc) {
	# N - number of scenarios
	# Mvdc - multivariate distribution object from 'copula' pacakge
	if (N < 1) stop(' Неправильное число сценариев')
	# let the start value of constraint variable be below zero
	s <- -1
	while (min(s) < 0) {
		if (N == 1) {
			R <- rMvdc(2, Mvdc)[,1]
			s <- as.numeric(mldivide(R + 1, matrix(1, length(R), 1)))
		}
		else {
			R <- rMvdc(N, Mvdc)
			s <- as.numeric(mldivide(t(R + 1), matrix(1, ncol(R), 1)))
		}
	}
	return(R)
}

# Function to generate a sample vine copula
bootVineCopula <- function(data, procedures = 200, N = nrow(data)) {
	# data is our observations
	# procedures - number of bootstrap loops
	# n - number of simulated points in every procedure
	Dim <- ncol(data) # dimension of copula
	Rows <- nrow(data) # number of data points
	data <- as.matrix(data)
	replicate(procedures, {
		samples <- sample(1:Rows, replace=T) # random numbers
		dataBoot <- data[samples,] # generate data bootstrap
		x <- pobs(dataBoot) # pseudo-observations
		# Fit the copula
		structure <- RVineStructureSelect(x)
		# Create a vine copula object
		copula <- vineCopula(structure)
		# Show the progress
		cat('=')
		# Generate the sample
		rCopula(N, copula)
	}
)}

# Unconditional Kupiec test for VaR
kupiec.test <- function(actual, VaR, level = 0.95) {
	L <- length(actual)
	K <- sum(actual < VaR)
	a0 <- K/L
	S <- 2*log(((1 - a0)/(1 - level))^(L - K)*(a0/level)^K)
	names(S) <- 'Likelihood ratio statistic'
	PVAL <- 1 - pchisq(S, 1)
	names(PVAL) <- "Kupiec test's p-value"
	DNAME <- paste0(deparse(substitute(actual)), ', level = ', level*100, '%')
	METHOD <- "Kupiec test of VaR (unconditional coverage VaR exceedance test)"
	Results <- list(statistic = S, p.value = PVAL, data.name = DNAME, method = METHOD)
	class(Results) = 'htest'
	Results
}

boxMtest <- function(observations, CorOrCov = c('cov', 'cor'), Method = 'pearson') {
	# Box's M test of covariance matrices equality
	
  # Covariance or correlation
  CorOrCov <- match.arg(CorOrCov)
	# number of populations
	m <- length(observations)
	# number of variables (must be equal)
	k <- sapply(observations, ncol)
	# variables number check
	if (!all(k == sum(k)/m)) 
		stop('Observations with the same number of variables must be used!')
	k <- sum(k)/m
	# number of observations in each population
	n <- sapply(observations, nrow)
	# n-value
	N <- sum(n)
	
	# construct the list of covariance matrices
	matrixList <- lapply(observations, CorOrCov, method = Method)
	
	# Calculate pooled covariance matrix
	S <- 0
	for (j in 1:m) S <- S + (n[j] - 1) * matrixList[[j]]
	S <- S / (N - m)
	
	# Calculate M 
	M <- 0
	for (j in 1:m) { 
		if (det(matrixList[[j]]) == 0)
			stop(paste0('|S', j, '| = 0, thus M is undefined. Test failed.'))
		M <- M + (n[j] - 1) * log(det(matrixList[[j]]))
	}
	names(M) <- NULL
	M <- (N - m) * log(det(S)) - M
	
	# Calculate c
	c <- sum(sapply(1:m, function(j) 1/(n[j] - 1) - 1/(N-m)))
	c <- c * (2*k^2 + 3*k - 1) / 6 / (k+1) / (m-1)
	
	# Test's statistic
	boxM <- M * (1-c)
	names(boxM) <- 'Chi-squared statistic'
	# Chi-Squared distribution's deegrees of freedom
	df <- k * (k+1) * (m-1) / 2
	# Test's p-value
	pVal <- 1 - pchisq(M*(1-c), df)
	names(pVal) <- "Box's M test's p-value"
	
	DNAME <- paste0(deparse(substitute(observations)), 
	                '\nMethod = "', Method, '"')
	METHOD <- paste("Box's M test of", 
                  switch(CorOrCov, cor = 'correlation', 
                         cov = 'covariance'), 
	                "matrices equality")
	Results <- list(statistic = boxM, p.value = pVal, 
					data.name = DNAME, method = METHOD)
	class(Results) <- 'htest'
	return(Results)
}

